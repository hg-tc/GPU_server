"""
GPU Model Server - PaddleOCR 3.x Version
=========================================
æ”¯æŒ:
- PDF è½¬ Markdown (PP-StructureV3)
- å›¾ç‰‡ OCR (PaddleOCR 3.x)
- æ–‡æ¡£ç‰ˆé¢åˆ†æ (PP-StructureV3)
- æ–‡æœ¬åµŒå…¥ (sentence-transformers)
- æ–‡æœ¬é‡æ’åº (FlagEmbedding)
"""

import logging
import os
import tempfile
import time
from datetime import datetime
from typing import List, Optional, Dict, Any
from pathlib import Path
import base64
import io

from fastapi import FastAPI, UploadFile, File, HTTPException, Request, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.exceptions import HTTPException as StarletteHTTPException
from pydantic import BaseModel
import torch

# ============================================
# æ—¥å¿—é…ç½®
# ============================================
def setup_logging():
    """é…ç½®è¯¦ç»†çš„æ—¥å¿—ç³»ç»Ÿ"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    log_format = "%(asctime)s [%(levelname)-8s] [%(name)s] %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"
    
    file_handler = logging.FileHandler(
        log_dir / "gpu_server.log",
        encoding="utf-8",
        mode="a"
    )
    file_handler.setLevel(logging.DEBUG)
    file_handler.setFormatter(logging.Formatter(log_format, date_format))
    
    error_handler = logging.FileHandler(
        log_dir / "gpu_server_error.log",
        encoding="utf-8",
        mode="a"
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(logging.Formatter(log_format, date_format))
    
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(logging.Formatter(log_format, date_format))
    
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)
    root_logger.handlers.clear()
    root_logger.addHandler(file_handler)
    root_logger.addHandler(error_handler)
    root_logger.addHandler(console_handler)
    
    logger = logging.getLogger("gpu_server")
    logger.setLevel(logging.DEBUG)
    
    # é™ä½ç¬¬ä¸‰æ–¹åº“æ—¥å¿—çº§åˆ«
    logging.getLogger("uvicorn").setLevel(logging.INFO)
    logging.getLogger("uvicorn.access").setLevel(logging.INFO)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("paddle").setLevel(logging.WARNING)
    
    return logger

logger = setup_logging()

# ============================================
# GPU æ£€æµ‹
# ============================================
def detect_device():
    """æ£€æµ‹å¯ç”¨è®¾å¤‡"""
    # æ£€æŸ¥ PaddlePaddle GPU
    try:
        import paddle
        if paddle.device.is_compiled_with_cuda():
            gpu_count = paddle.device.cuda.device_count()
            if gpu_count > 0:
                logger.info("=" * 60)
                logger.info("ğŸš€ PaddlePaddle GPU æ£€æµ‹:")
                logger.info(f"  âœ… CUDA å¯ç”¨")
                logger.info(f"  ğŸ® GPU æ•°é‡: {gpu_count}")
                for i in range(gpu_count):
                    props = paddle.device.cuda.get_device_properties(i)
                    logger.info(f"  ğŸ¯ GPU {i}: {props.name}")
                logger.info("=" * 60)
                return "gpu"
    except Exception as e:
        logger.warning(f"PaddlePaddle GPU æ£€æµ‹å¤±è´¥: {e}")
    
    # æ£€æŸ¥ PyTorch GPU
    try:
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            logger.info("=" * 60)
            logger.info("ğŸš€ PyTorch GPU æ£€æµ‹:")
            logger.info(f"  âœ… CUDA å¯ç”¨")
            logger.info(f"  ğŸ® GPU æ•°é‡: {gpu_count}")
            for i in range(gpu_count):
                props = torch.cuda.get_device_properties(i)
                logger.info(f"  ğŸ¯ GPU {i}: {props.name}")
                logger.info(f"     æ˜¾å­˜: {props.total_memory / 1024**3:.2f} GB")
            logger.info("=" * 60)
            return "cuda"
    except Exception as e:
        logger.warning(f"PyTorch GPU æ£€æµ‹å¤±è´¥: {e}")
    
    logger.warning("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œå°†ä½¿ç”¨ CPU")
    return "cpu"

DEVICE = detect_device()

# ============================================
# FastAPI åº”ç”¨
# ============================================
app = FastAPI(
    title="GPU Model Server - PaddleOCR 3.x",
    version="3.0.0",
    description="PDF/å›¾ç‰‡å¤„ç†ã€OCRã€åµŒå…¥ã€é‡æ’åºæœåŠ¡",
)

# è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶
class RequestLoggingMiddleware(BaseHTTPMiddleware):
    WARNING_TIMEOUT = 60
    CRITICAL_TIMEOUT = 300
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        client_ip = request.client.host if request.client else "unknown"
        
        logger.info(f"[è¯·æ±‚å¼€å§‹] {request.method} {request.url.path} | å®¢æˆ·ç«¯: {client_ip}")
        
        try:
            response = await call_next(request)
            process_time = time.time() - start_time
            
            if process_time > self.CRITICAL_TIMEOUT:
                logger.warning(f"[è¯·æ±‚è¶…æ—¶] âš ï¸âš ï¸âš ï¸ {request.url.path} | è€—æ—¶: {process_time:.3f}s")
            elif process_time > self.WARNING_TIMEOUT:
                logger.warning(f"[è¯·æ±‚è¶…æ—¶] âš ï¸ {request.url.path} | è€—æ—¶: {process_time:.3f}s")
            
            status_emoji = "âœ…" if 200 <= response.status_code < 300 else "âŒ"
            logger.info(f"[è¯·æ±‚å®Œæˆ] {status_emoji} {request.url.path} | çŠ¶æ€: {response.status_code} | è€—æ—¶: {process_time:.3f}s")
            
            return response
        except Exception as e:
            process_time = time.time() - start_time
            logger.error(f"[è¯·æ±‚å¼‚å¸¸] âŒ {request.url.path} | é”™è¯¯: {e} | è€—æ—¶: {process_time:.3f}s", exc_info=True)
            raise

app.add_middleware(RequestLoggingMiddleware)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å¼‚å¸¸å¤„ç†
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"[å…¨å±€å¼‚å¸¸] {request.url.path} | {type(exc).__name__}: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"detail": f"Internal server error: {str(exc)}", "error_type": type(exc).__name__}
    )

@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    return JSONResponse(status_code=exc.status_code, content={"detail": exc.detail})

# ============================================
# æ¨¡å‹å•ä¾‹ç®¡ç†
# ============================================
_ocr_engine = None
_structure_engine = None
_embedder = None
_reranker = None

def _get_ocr_engine():
    """è·å– PaddleOCR 3.x å¼•æ“"""
    global _ocr_engine
    if _ocr_engine is None:
        try:
            from paddleocr import PaddleOCR
            logger.info("åˆå§‹åŒ– PaddleOCR 3.x...")
            
            device = "gpu" if DEVICE in ["gpu", "cuda"] else "cpu"
            _ocr_engine = PaddleOCR(
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                use_textline_orientation=False,
                device=device,
            )
            logger.info(f"PaddleOCR 3.x åˆå§‹åŒ–æˆåŠŸ | device={device}")
        except Exception as e:
            logger.error(f"PaddleOCR åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    return _ocr_engine


def _get_structure_engine():
    """è·å– PP-StructureV3 å¼•æ“"""
    global _structure_engine
    if _structure_engine is None:
        try:
            from paddleocr import PPStructureV3
            logger.info("åˆå§‹åŒ– PP-StructureV3...")
            
            device = "gpu" if DEVICE in ["gpu", "cuda"] else "cpu"
            _structure_engine = PPStructureV3(
                use_doc_orientation_classify=False,
                use_doc_unwarping=False,
                device=device,
            )
            logger.info(f"PP-StructureV3 åˆå§‹åŒ–æˆåŠŸ | device={device}")
        except Exception as e:
            logger.error(f"PP-StructureV3 åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    return _structure_engine


def _get_embedder():
    """è·å–åµŒå…¥æ¨¡å‹"""
    global _embedder
    if _embedder is None:
        try:
            from sentence_transformers import SentenceTransformer
            
            model_name = os.getenv("EMBED_MODEL_NAME", "BAAI/bge-large-zh-v1.5")
            device = "cuda" if DEVICE in ["gpu", "cuda"] else "cpu"
            
            logger.info(f"åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {model_name} | device={device}")
            _embedder = SentenceTransformer(model_name, device=device)
            logger.info("åµŒå…¥æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    return _embedder


def _get_reranker():
    """è·å–é‡æ’åºæ¨¡å‹"""
    global _reranker
    if _reranker is None:
        try:
            from FlagEmbedding import FlagReranker
            
            model_name = os.getenv("RERANKER_MODEL_NAME", "BAAI/bge-reranker-v2-m3")
            device = "cuda" if DEVICE in ["gpu", "cuda"] else "cpu"
            use_fp16 = device == "cuda"
            
            logger.info(f"åˆå§‹åŒ–é‡æ’åºæ¨¡å‹: {model_name} | device={device}")
            _reranker = FlagReranker(model_name, use_fp16=use_fp16, device=device)
            logger.info("é‡æ’åºæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        except ImportError:
            from sentence_transformers import CrossEncoder
            logger.warning("FlagEmbedding ä¸å¯ç”¨ï¼Œä½¿ç”¨ CrossEncoder")
            _reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-12-v2", device=device)
        except Exception as e:
            logger.error(f"é‡æ’åºæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    return _reranker

# ============================================
# ç»Ÿè®¡ä¿¡æ¯
# ============================================
_server_start_time = time.time()
_request_stats = {
    "ocr_total": 0, "ocr_success": 0, "ocr_failed": 0,
    "structure_total": 0, "structure_success": 0, "structure_failed": 0,
    "pdf_total": 0, "pdf_success": 0, "pdf_failed": 0,
    "embed_total": 0, "embed_success": 0, "embed_failed": 0,
    "rerank_total": 0, "rerank_success": 0, "rerank_failed": 0,
}

# ============================================
# API ç«¯ç‚¹
# ============================================

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    status = {
        "status": "ok",
        "timestamp": datetime.now().isoformat(),
        "version": "3.0.0",
        "device": DEVICE,
    }
    
    # GPU ä¿¡æ¯
    try:
        if torch.cuda.is_available():
            status["gpu"] = {
                "available": True,
                "device_count": torch.cuda.device_count(),
                "device_name": torch.cuda.get_device_name(0),
                "memory": {
                    "allocated_gb": round(torch.cuda.memory_allocated(0) / 1024**3, 2),
                    "reserved_gb": round(torch.cuda.memory_reserved(0) / 1024**3, 2),
                    "total_gb": round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 2),
                }
            }
        else:
            status["gpu"] = {"available": False}
    except Exception as e:
        status["gpu"] = {"available": False, "error": str(e)}
    
    # æ¨¡å‹çŠ¶æ€
    status["models"] = {
        "ocr": _ocr_engine is not None,
        "structure": _structure_engine is not None,
        "embedder": _embedder is not None,
        "reranker": _reranker is not None,
    }
    
    return status


@app.get("/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    return {
        "stats": _request_stats,
        "uptime_seconds": time.time() - _server_start_time,
    }


@app.post("/clear_cache")
async def clear_gpu_cache():
    """æ¸…ç† GPU ç¼“å­˜"""
    try:
        if torch.cuda.is_available():
            before = torch.cuda.memory_allocated(0) / 1024**3
            torch.cuda.empty_cache()
            after = torch.cuda.memory_allocated(0) / 1024**3
            return {"status": "ok", "freed_gb": round(before - after, 2)}
        return {"status": "ok", "message": "No GPU"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ============================================
# OCR ç«¯ç‚¹
# ============================================

class OCRResponse(BaseModel):
    text: str
    confidence: float
    lines: List[str]
    confidences: List[float]
    boxes: List[List[List[float]]]


@app.post("/ocr_image", response_model=OCRResponse)
async def ocr_image(file: UploadFile = File(...)) -> OCRResponse:
    """å›¾ç‰‡ OCR - ä½¿ç”¨ PaddleOCR 3.x"""
    global _request_stats
    _request_stats["ocr_total"] += 1
    
    start_time = time.time()
    tmp_path = None
    
    try:
        if not file.filename:
            raise HTTPException(status_code=400, detail="Empty filename")
        
        suffix = os.path.splitext(file.filename)[1].lower() or ".png"
        
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp_path = tmp.name
            content = await file.read()
            if not content:
                raise HTTPException(status_code=400, detail="Empty file")
            tmp.write(content)
        
        ocr = _get_ocr_engine()
        
        # PaddleOCR 3.x ä½¿ç”¨ predict æ–¹æ³•
        results = ocr.predict(tmp_path)
        
        lines = []
        confidences = []
        boxes = []
        
        for res in results:
            # è·å–ç»“æœæ•°æ®
            if hasattr(res, 'rec_texts') and hasattr(res, 'rec_scores') and hasattr(res, 'rec_polys'):
                rec_texts = res.rec_texts if hasattr(res, 'rec_texts') else []
                rec_scores = res.rec_scores if hasattr(res, 'rec_scores') else []
                rec_polys = res.rec_polys if hasattr(res, 'rec_polys') else []
                
                for i, text in enumerate(rec_texts):
                    if text:
                        lines.append(text)
                        confidences.append(float(rec_scores[i]) if i < len(rec_scores) else 0.0)
                        if i < len(rec_polys):
                            boxes.append(rec_polys[i].tolist() if hasattr(rec_polys[i], 'tolist') else rec_polys[i])
            elif hasattr(res, 'json'):
                # å°è¯•ä» json å±æ€§è·å–
                data = res.json
                if 'rec_texts' in data:
                    for i, text in enumerate(data['rec_texts']):
                        if text:
                            lines.append(text)
                            confidences.append(float(data['rec_scores'][i]) if i < len(data.get('rec_scores', [])) else 0.0)
        
        full_text = "\n".join(lines)
        avg_conf = sum(confidences) / len(confidences) if confidences else 0.0
        
        elapsed = time.time() - start_time
        logger.info(f"[OCR] âœ… å®Œæˆ | æ–‡ä»¶: {file.filename} | æ–‡æœ¬é•¿åº¦: {len(full_text)} | ç½®ä¿¡åº¦: {avg_conf:.4f} | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["ocr_success"] += 1
        return OCRResponse(
            text=full_text,
            confidence=avg_conf,
            lines=lines,
            confidences=confidences,
            boxes=boxes,
        )
    
    except HTTPException:
        _request_stats["ocr_failed"] += 1
        raise
    except Exception as e:
        _request_stats["ocr_failed"] += 1
        logger.error(f"[OCR] âŒ å¤±è´¥ | æ–‡ä»¶: {file.filename} | é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"OCR failed: {e}")
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass


class OCRBase64Request(BaseModel):
    image_base64: str
    filename: Optional[str] = "image.png"


@app.post("/ocr_base64", response_model=OCRResponse)
async def ocr_base64(request: OCRBase64Request) -> OCRResponse:
    """Base64 å›¾ç‰‡ OCR"""
    global _request_stats
    _request_stats["ocr_total"] += 1
    
    start_time = time.time()
    tmp_path = None
    
    try:
        # è§£ç  base64
        image_data = base64.b64decode(request.image_base64)
        
        suffix = os.path.splitext(request.filename)[1].lower() or ".png"
        
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp_path = tmp.name
            tmp.write(image_data)
        
        ocr = _get_ocr_engine()
        results = ocr.predict(tmp_path)
        
        lines = []
        confidences = []
        boxes = []
        
        for res in results:
            if hasattr(res, 'rec_texts'):
                for i, text in enumerate(res.rec_texts):
                    if text:
                        lines.append(text)
                        confidences.append(float(res.rec_scores[i]) if i < len(res.rec_scores) else 0.0)
        
        full_text = "\n".join(lines)
        avg_conf = sum(confidences) / len(confidences) if confidences else 0.0
        
        elapsed = time.time() - start_time
        logger.info(f"[OCR-Base64] âœ… å®Œæˆ | æ–‡æœ¬é•¿åº¦: {len(full_text)} | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["ocr_success"] += 1
        return OCRResponse(
            text=full_text,
            confidence=avg_conf,
            lines=lines,
            confidences=confidences,
            boxes=boxes,
        )
    
    except Exception as e:
        _request_stats["ocr_failed"] += 1
        logger.error(f"[OCR-Base64] âŒ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"OCR failed: {e}")
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass


# ============================================
# æ–‡æ¡£ç»“æ„åˆ†æç«¯ç‚¹
# ============================================

class StructureResponse(BaseModel):
    markdown: str
    layout_info: Optional[Dict[str, Any]] = None


@app.post("/structure_image", response_model=StructureResponse)
async def structure_image(file: UploadFile = File(...)) -> StructureResponse:
    """å›¾ç‰‡ç‰ˆé¢åˆ†æ - ä½¿ç”¨ PP-StructureV3"""
    global _request_stats
    _request_stats["structure_total"] += 1
    
    start_time = time.time()
    tmp_path = None
    
    try:
        suffix = os.path.splitext(file.filename)[1].lower() or ".png"
        
        with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
            tmp_path = tmp.name
            content = await file.read()
            tmp.write(content)
        
        structure = _get_structure_engine()
        results = structure.predict(tmp_path)
        
        markdown_text = ""
        layout_info = {}
        
        for res in results:
            if hasattr(res, 'markdown'):
                md_info = res.markdown
                if isinstance(md_info, dict):
                    markdown_text = md_info.get('markdown_text', '')
                elif isinstance(md_info, str):
                    markdown_text = md_info
            
            if hasattr(res, 'json'):
                layout_info = res.json
        
        elapsed = time.time() - start_time
        logger.info(f"[Structure] âœ… å®Œæˆ | æ–‡ä»¶: {file.filename} | Markdowné•¿åº¦: {len(markdown_text)} | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["structure_success"] += 1
        return StructureResponse(markdown=markdown_text, layout_info=layout_info)
    
    except Exception as e:
        _request_stats["structure_failed"] += 1
        logger.error(f"[Structure] âŒ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Structure analysis failed: {e}")
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass


@app.post("/structure_pdf")
async def structure_pdf(file: UploadFile = File(...)):
    """PDF ç‰ˆé¢åˆ†æ - ä½¿ç”¨ PP-StructureV3"""
    global _request_stats
    _request_stats["structure_total"] += 1
    
    start_time = time.time()
    tmp_path = None
    
    try:
        if not file.filename.lower().endswith(".pdf"):
            raise HTTPException(status_code=400, detail="Only PDF files supported")
        
        with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
            tmp_path = tmp.name
            content = await file.read()
            tmp.write(content)
        
        structure = _get_structure_engine()
        results = structure.predict(tmp_path)
        
        # åˆå¹¶æ‰€æœ‰é¡µé¢çš„ Markdown
        markdown_list = []
        for res in results:
            if hasattr(res, 'markdown'):
                md_info = res.markdown
                markdown_list.append(md_info)
        
        # ä½¿ç”¨ PP-StructureV3 çš„åˆå¹¶æ–¹æ³•
        if hasattr(structure, 'concatenate_markdown_pages'):
            full_markdown = structure.concatenate_markdown_pages(markdown_list)
        else:
            full_markdown = "\n\n---\n\n".join([
                m.get('markdown_text', '') if isinstance(m, dict) else str(m)
                for m in markdown_list
            ])
        
        elapsed = time.time() - start_time
        logger.info(f"[Structure-PDF] âœ… å®Œæˆ | æ–‡ä»¶: {file.filename} | é¡µæ•°: {len(markdown_list)} | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["structure_success"] += 1
        return {
            "content": full_markdown,
            "page_count": len(markdown_list),
            "conversion_method": "PP-StructureV3",
        }
    
    except HTTPException:
        _request_stats["structure_failed"] += 1
        raise
    except Exception as e:
        _request_stats["structure_failed"] += 1
        logger.error(f"[Structure-PDF] âŒ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"PDF structure analysis failed: {e}")
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass


# ============================================
# PDF è½¬ Markdown ç«¯ç‚¹
# ============================================

@app.post("/pdf_to_markdown")
async def pdf_to_markdown(file: UploadFile = File(...)):
    """PDF è½¬ Markdown (ä½¿ç”¨ PP-StructureV3)"""
    global _request_stats
    _request_stats["pdf_total"] += 1
    
    start_time = time.time()
    tmp_path = None
    
    try:
        if not file.filename.lower().endswith(".pdf"):
            raise HTTPException(status_code=400, detail="Only PDF files supported")
        
        with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
            tmp_path = tmp.name
            content = await file.read()
            file_size = len(content)
            tmp.write(content)
        
        logger.info(f"[PDF] å¼€å§‹å¤„ç† | æ–‡ä»¶: {file.filename} | å¤§å°: {file_size/1024/1024:.2f}MB")
        
        # ä½¿ç”¨ PP-StructureV3
        structure = _get_structure_engine()
        results = structure.predict(tmp_path)
        
        markdown_list = []
        for res in results:
            if hasattr(res, 'markdown'):
                markdown_list.append(res.markdown)
        
        if hasattr(structure, 'concatenate_markdown_pages'):
            markdown = structure.concatenate_markdown_pages(markdown_list)
        else:
            markdown = "\n\n---\n\n".join([
                m.get('markdown_text', '') if isinstance(m, dict) else str(m)
                for m in markdown_list
            ])
        
        if not markdown:
            raise HTTPException(status_code=500, detail="Empty output")
        
        elapsed = time.time() - start_time
        logger.info(f"[PDF] âœ… å®Œæˆ | æ–‡ä»¶: {file.filename} | è¾“å‡º: {len(markdown)} chars | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["pdf_success"] += 1
        return {
            "content": markdown,
            "conversion_method": "PP-StructureV3",
            "file_name": file.filename,
        }
    
    except HTTPException:
        _request_stats["pdf_failed"] += 1
        raise
    except Exception as e:
        _request_stats["pdf_failed"] += 1
        logger.error(f"[PDF] âŒ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"PDF conversion failed: {e}")
    finally:
        if tmp_path and os.path.exists(tmp_path):
            try:
                os.unlink(tmp_path)
            except:
                pass


# ============================================
# åµŒå…¥ç«¯ç‚¹
# ============================================

class EmbedRequest(BaseModel):
    texts: List[str]


class EmbedResponse(BaseModel):
    embeddings: List[List[float]]


@app.post("/embed", response_model=EmbedResponse)
async def embed(request: EmbedRequest) -> EmbedResponse:
    """æ–‡æœ¬åµŒå…¥"""
    global _request_stats
    _request_stats["embed_total"] += 1
    
    start_time = time.time()
    
    if not request.texts:
        return EmbedResponse(embeddings=[])
    
    try:
        model = _get_embedder()
        vectors = model.encode(request.texts, normalize_embeddings=True)
        embeddings = vectors.tolist()
        
        elapsed = time.time() - start_time
        logger.info(f"[Embed] âœ… å®Œæˆ | æ–‡æœ¬æ•°: {len(request.texts)} | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["embed_success"] += 1
        return EmbedResponse(embeddings=embeddings)
    
    except Exception as e:
        _request_stats["embed_failed"] += 1
        logger.error(f"[Embed] âŒ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Embedding failed: {e}")


class BatchEmbedRequest(BaseModel):
    batches: List[List[str]]


class BatchEmbedResponse(BaseModel):
    embeddings: List[List[List[float]]]
    batch_times: List[float]


@app.post("/embed_batch", response_model=BatchEmbedResponse)
async def embed_batch(request: BatchEmbedRequest) -> BatchEmbedResponse:
    """æ‰¹é‡æ–‡æœ¬åµŒå…¥"""
    global _request_stats
    _request_stats["embed_total"] += 1
    
    if not request.batches:
        return BatchEmbedResponse(embeddings=[], batch_times=[])
    
    try:
        model = _get_embedder()
        all_embeddings = []
        batch_times = []
        
        for batch in request.batches:
            if not batch:
                all_embeddings.append([])
                batch_times.append(0)
                continue
            
            batch_start = time.time()
            vectors = model.encode(batch, normalize_embeddings=True)
            batch_time = time.time() - batch_start
            
            all_embeddings.append(vectors.tolist())
            batch_times.append(round(batch_time, 3))
        
        _request_stats["embed_success"] += 1
        return BatchEmbedResponse(embeddings=all_embeddings, batch_times=batch_times)
    
    except Exception as e:
        _request_stats["embed_failed"] += 1
        raise HTTPException(status_code=500, detail=f"Batch embedding failed: {e}")


# ============================================
# é‡æ’åºç«¯ç‚¹
# ============================================

class RerankRequest(BaseModel):
    query: str
    documents: List[str]


class RerankResponse(BaseModel):
    scores: List[float]


@app.post("/rerank", response_model=RerankResponse)
async def rerank(request: RerankRequest) -> RerankResponse:
    """æ–‡æ¡£é‡æ’åº"""
    global _request_stats
    _request_stats["rerank_total"] += 1
    
    start_time = time.time()
    
    if not request.documents:
        return RerankResponse(scores=[])
    
    try:
        reranker = _get_reranker()
        pairs = [[request.query, doc or ""] for doc in request.documents]
        
        if hasattr(reranker, "compute_score"):
            scores = reranker.compute_score(pairs)
        else:
            scores = reranker.predict(pairs)
        
        try:
            scores_list = list(scores)
        except TypeError:
            scores_list = [scores]
        
        scores_list = [float(s) for s in scores_list]
        
        elapsed = time.time() - start_time
        logger.info(f"[Rerank] âœ… å®Œæˆ | æ–‡æ¡£æ•°: {len(request.documents)} | è€—æ—¶: {elapsed:.3f}s")
        
        _request_stats["rerank_success"] += 1
        return RerankResponse(scores=scores_list)
    
    except Exception as e:
        _request_stats["rerank_failed"] += 1
        logger.error(f"[Rerank] âŒ å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Rerank failed: {e}")


# ============================================
# å¯åŠ¨å…¥å£
# ============================================

if __name__ == "__main__":
    import uvicorn
    
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    
    logger.info(f"å¯åŠ¨ GPU Server | host={host} | port={port}")
    uvicorn.run(app, host=host, port=port)
